{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a6ad6d-6fd8-49e2-af31-6404963a693f",
   "metadata": {},
   "source": [
    "# 3. Create a digit embedding space\n",
    "The third task is to use the trained network as an embedding space for images of written symbols. In this case, you'll use it to differentiate images of the greek letters alpha, beta, and gamma. Make new code files from the prior tasks. Read in your trained network as the first step and make a submodel that includes everything but the output layer..\n",
    "\n",
    "embedding space just means everything up until the classification layer?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f84ef4-405a-47c3-a537-58d464b4fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to move files\n",
    "import os\n",
    "import shutil\n",
    "from os import walk\n",
    "from os.path import exists\n",
    "\n",
    "# import previous notebook\n",
    "import nbimporter\n",
    "import Task1AE as Note1AE\n",
    "import Task1FG as Note1FG\n",
    "\n",
    "# to save to csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d597a3-30e8-4b45-a4f6-59ca868f06ae",
   "metadata": {},
   "source": [
    "### A. Create a greek symbol data set\n",
    "Write a program to read in the images, scale them down to 28x28, convert them to greyscale, invert the intensities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b305a1-1591-44ca-b324-ce2fb4ca904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class Alphabet(Enum):\n",
    "    ALPHA = 0\n",
    "    BETA= 1\n",
    "    GAMMA = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd077b5-ebd7-413f-9795-ba80ad3be72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that create category folders inside the dataset folder\n",
    "# based on the filename. Then move the filenames to the correct folder\n",
    "def move_filenames_to_category_folder(dataset_name):\n",
    "    \n",
    "    # images/greek/\n",
    "    target_path = \"images/\" + dataset_name + \"/\"\n",
    "    \n",
    "    # 1. get all filenames in the folder\n",
    "    all_filenames = []\n",
    "    for (dirpath, dirnames, filenames) in walk(target_path):\n",
    "        if(dirpath == target_path):\n",
    "            # get unique filenames\n",
    "            all_filenames = filenames\n",
    "\n",
    "    # 2. grab all the letters\n",
    "    alphabet = []\n",
    "    for filename in all_filenames:\n",
    "        letter = filename.split(\"_\")[0]\n",
    "        alphabet.append(letter)\n",
    "\n",
    "    # 3. remove duplicates\n",
    "    alphabet = list(set(alphabet))\n",
    "    \n",
    "    # 4. create unique folder\n",
    "    for letter in alphabet:\n",
    "        try:\n",
    "            # create folder\n",
    "            os.mkdir(target_path + letter)\n",
    "        except OSError as error: \n",
    "            print(error)  \n",
    "        \n",
    "    # 5. loop through each files again\n",
    "    for filename in os.listdir(target_path):\n",
    "        letter_bit = filename.split(\"_\")[0]\n",
    "        \n",
    "        if (letter_bit in alphabet and len(filename.split(\"_\")) > 1):\n",
    "            old_path = target_path + filename\n",
    "            new_path = target_path + letter_bit + \"/\" + filename \n",
    "            # move this file to the correct category folder\n",
    "            shutil.move(old_path, new_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561eb25-c4af-4127-9273-8bace481bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that takes in a dataset name from local \"images/\" directory and batch size and\n",
    "# upload the images to PyTorch's ImageFolder\n",
    "# it returns a dataLoader object\n",
    "def upload_to_ImageFolder(dataset_name, batch_size):\n",
    "    # - set up the transformation for our dataset\n",
    "    transform = transforms.Compose(\n",
    "                [transforms.Resize(28),\n",
    "                 transforms.Grayscale(),\n",
    "                 transforms.RandomInvert(p=1),\n",
    "                 transforms.ToTensor(),\n",
    "                 # normalize with mean and std\n",
    "                 transforms.Normalize((0.1307,), (0.3801,)),\n",
    "                ])\n",
    "\n",
    "    # - create the dataset from our images folder to datasets\n",
    "    dataset = datasets.ImageFolder(\"images/\" + dataset_name, transform=transform)\n",
    "\n",
    "    # - get dataloader for our 10 images\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=30, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b923a587-cc49-422b-9e15-d5bedc6b834b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ce39c2-34f2-468a-969e-60ea81d60f4e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A function that, given a dataloader will extract the data and target \n",
    "# and save them both as two separate csv files. \n",
    "# if isOverwrite is false, it will not write anything if data already exists\n",
    "def save_data_as_csv(dataloader, dataset_name, isOverwrite):\n",
    "    data_filename = dataset_name + '.csv'\n",
    "    target_filename = dataset_name + '_target.csv'\n",
    "    \n",
    "    if(isOverwrite):\n",
    "        isWrite = True\n",
    "    else:\n",
    "        # not overwrite means if file already exists dont write\n",
    "        isWrite = not(os.path.exists(data_filename))\n",
    "    \n",
    "\n",
    "    if(isWrite):\n",
    "        # 1. load the data\n",
    "        data, target = next(iter(dataloader))\n",
    "        csv_np = np.array([])\n",
    "\n",
    "\n",
    "        # 2. create empty csv file with the headers\n",
    "        header_list = list(map(str, range(0, 784)))\n",
    "        header_str = ','.join(header_list)\n",
    "        with open(data_filename, 'w') as csvfile:\n",
    "            np.savetxt(csvfile, [], header=header_str,\n",
    "                    delimiter=',', fmt='%s', comments='')\n",
    "\n",
    "        with open(target_filename, 'w') as csvtargetfile:\n",
    "            np.savetxt(csvtargetfile, [], header=\"category\",\n",
    "                    delimiter=',', fmt='%s', comments='')\n",
    "\n",
    "        # 3. loop through each image and append to csv\n",
    "        for i in range(len(data)):\n",
    "            print(\"\\nindex:>>>>\", i)\n",
    "            # - display the image info\n",
    "            img_mat = data[i][0]\n",
    "            ground_truth = target[i].numpy()\n",
    "            print(\"ground truth:\", Alphabet(ground_truth))\n",
    "            plt.imshow(img_mat, cmap=\"gray\", interpolation=\"none\")\n",
    "            plt.show()\n",
    "\n",
    "            # - create a new csv row\n",
    "            csv_row_np = np.array([])\n",
    "\n",
    "            # - for each row in a single image\n",
    "            for img_row in img_mat:\n",
    "\n",
    "                # - append it as a single row\n",
    "                img_row_np = img_row.numpy()\n",
    "                csv_row_np = np.append(csv_row_np, [img_row_np])\n",
    "\n",
    "            # - append this image row and target in csv file\n",
    "            with open(data_filename, 'a') as csvfile:\n",
    "                np.savetxt(csvfile, [csv_row_np], delimiter=',', fmt='%s', comments='')\n",
    "\n",
    "            with open(target_filename, 'a') as csvtargetfile:\n",
    "                np.savetxt(csvtargetfile, [ground_truth],\n",
    "                        delimiter=',', fmt='%s', comments='')\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb32363-d0aa-4913-803f-e11be665ea7a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. sort filenames to category folder\n",
    "dataset_name = \"greek\"\n",
    "move_filenames_to_category_folder(dataset_name)    \n",
    "\n",
    "# 2. upload files to Pytorch ImageFolder\n",
    "batch_size = 30\n",
    "dataloader = upload_to_ImageFolder(dataset_name, batch_size)\n",
    "\n",
    "# 3. check the single value in OWN dataset\n",
    "data, target = next(iter(dataloader))\n",
    "print(\"single image>>>>>: \", data[0])\n",
    "print(\"shape: \", data[0].shape)\n",
    "\n",
    "# 3. display image\n",
    "Note1AE.display_sample_images(dataloader)\n",
    "\n",
    "# 4. save data as csv\n",
    "save_data_as_csv(dataloader, \"greek\", isOverwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b48d1e3-17d1-4829-8d36-3814b54ffcac",
   "metadata": {},
   "source": [
    "## B. Create Truncated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9d01f1-d367-4b82-97cc-e937d0463734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
